{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "\n",
    "#importing SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# spark builder\n",
    "spark = SparkSession.builder.appName(\"Wine\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "\n",
    "# import SparkFiles, add file url\n",
    "from pyspark import SparkFiles\n",
    "\n",
    "url =\"https://s3.amazonaws.com/dataviz-curriculum/day_1/wine.csv\"\n",
    "spark.sparkContext.addFile(url)\n",
    "wine_df = spark.read.csv(SparkFiles.get(\"wine.csv\"), sep=\",\", header=True)\n",
    "\n",
    "# display the data \n",
    "wine_df.show()\n",
    "\n",
    "-------+--------------------+--------------------+------+-----+--------------+-----------------+-----------------+------------------+--------------------+\n",
    "|country|         description|         designation|points|price|      province|         region_1|         region_2|           variety|              winery|\n",
    "+-------+--------------------+--------------------+------+-----+--------------+-----------------+-----------------+------------------+--------------------+\n",
    "|     US|This tremendous 1...|   Martha's Vineyard|    96|  235|    California|      Napa Valley|             Napa|Cabernet Sauvignon|               Heitz|\n",
    "|  Spain|Ripe aromas of fi...|Carodorum Selecci...|    96|  110|Northern Spain|             Toro|             null|     Tinta de Toro|Bodega Carmen Rod...|\n",
    "|     US|Mac Watson honors...|Special Selected ...|    96|   90|    California|   Knights Valley|           Sonoma|   Sauvignon Blanc|            Macauley|\n",
    "|     US|This spent 20 mon...|             Reserve|    96|   65|        Oregon|Willamette Valley|Willamette Valley|        Pinot Noir|               Ponzi|\n",
    "+-------+--------------------+--------------------+------+-----+--------------+-----------------+-----------------+------------------+--------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "# Inspect the data types by printing the schema\n",
    "\n",
    "wine_df.printSchema()\n",
    "root\n",
    " |-- country: string (nullable = true)\n",
    " |-- description: string (nullable = true)\n",
    " |-- designation: string (nullable = true)\n",
    " |-- points: string (nullable = true)\n",
    " |-- price: string (nullable = true)\n",
    " |-- province: string (nullable = true)\n",
    " |-- region_1: string (nullable = true)\n",
    " |-- region_2: string (nullable = true)\n",
    " |-- variety: string (nullable = true)\n",
    " |-- winery: string (nullable = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "# Change the data type\n",
    "# Import struct fields first\n",
    "\n",
    "from pyspark.sql.types import StructField, StringType, IntegerType, StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "\n",
    "# Next we need to create the list of struct fields\n",
    "schema = [StructField(\"points\", IntegerType(), True), StructField(\"price\", IntegerType(), True)]\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "\n",
    "# Pass in our fields \n",
    "final = StructType(fields = schema)\n",
    "final\n",
    "\n",
    "StructType(List(StructField(points,IntegerType,true),StructField(price,IntegerType,true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "\n",
    "# Read our data with our new schema\n",
    "wine_dataframe = spark.read.csv(SparkFiles.get(\"wine.csv\"), sep=\",\", header=True, schema=final)\n",
    "wine_dataframe\n",
    "\n",
    "DataFrame[points: int, price: int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "\n",
    "# Print it out\n",
    "wine_dataframe.printSchema()\n",
    "\n",
    "\n",
    " |-- points: integer (nullable = true)\n",
    " |-- price: integer (nullable = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "\n",
    "# Order a dataframe by ascending values\n",
    "df.orderBy(df[\"points\"].asc()).head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
